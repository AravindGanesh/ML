{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden Markov Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 922,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 923,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset():\n",
    "    def __init__(self,folder):\n",
    "        self.folder = folder\n",
    "        self.phones = os.listdir(folder)\n",
    "        self.sr = 8000 # sampling rate of given audio files\n",
    "        self.window = int(25*1e-3 * self.sr) # 25ms window\n",
    "        self.overlap = int(10*1e-3 * self.sr) # 10ms overlap\n",
    "        self.hop = self.window -  self.overlap\n",
    "        \n",
    "    def get_features(self, wav_path):\n",
    "        y, self.sr = librosa.core.load(path=wav_path, sr=None, mono=True, duration=0.5)\n",
    "        num_windows = len(y)//self.window\n",
    "        x = librosa.feature.mfcc(y=y, sr=self.sr, n_mfcc=num_windows, n_fft=self.window, hop_length=len(y)//(13-1), n_mels=64) # x.shape = [num_windows, 13]\n",
    "        return x\n",
    "\n",
    "    def __call__(self):\n",
    "        train_wavs = np.random.choice(self.phones, 32, replace=False) # randomly pick 32 wav files for training among 36 files\n",
    "        test_wavs  = np.setdiff1d(self.phones, train_wavs, assume_unique=True) # take the rest 4 wav files as test data\n",
    "        train, test = [], [] \n",
    "        train = np.array([self.get_features(os.path.join(self.folder, wav)) for wav in train_wavs])\n",
    "        test  = np.array([self.get_features(os.path.join(self.folder, wav)) for wav in  test_wavs])\n",
    "        # normalize the data\n",
    "        train,test = train[:,1:,:], test[:,1:,:]\n",
    "        train = train/np.std(train,axis=0) - np.mean(train)\n",
    "        test  = test/np.std(test,axis=0)   - np.mean(test)\n",
    "        return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 924,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 19, 13), (4, 19, 13))"
      ]
     },
     "execution_count": 924,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = dataset('che/')()\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 925,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, mu, sigma):\n",
    "    d = len(x)\n",
    "    px = 1/np.sqrt(np.linalg.det(sigma) * ((2*np.pi)**d))\n",
    "    px *= np.exp(-0.5*np.matmul(np.matmul(np.transpose(x-mu), np.linalg.inv(sigma)), x-mu))\n",
    "    return px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Kmeans import Kmeans # Kmeans from previous assignment\n",
    "class HMM():\n",
    "    def __init__(self, K, trainset):\n",
    "        self.K = K # states\n",
    "        self.X = trainset\n",
    "        self.M, self.N, self.d = self.X.shape # M:number of sound files, N=states, d=13 \n",
    "        # initializing parameters\n",
    "        self.pi = np.random.uniform(high=1, low=0, size=self.K)\n",
    "        self.pi /= np.sum(self.pi)\n",
    "        self.A = np.triu(np.random.uniform(high=1, low=0, size=(self.K, self.K)))\n",
    "        self.A = np.transpose(self.A.T/np.sum(self.A, axis=1))\n",
    "        #initalization using kmeans\n",
    "        kmeans = Kmeans(X=self.X[0], K=self.K)\n",
    "        kmeans.cluster(n_iter=2)\n",
    "        self.means = kmeans.means # initialize means\n",
    "        # covariances are initalized by finding covariances of each cluster\n",
    "        mixtures = kmeans.get_clusters()\n",
    "        # print(mixtures[0].shape)\n",
    "        self.covars = np.zeros((self.K, self.d, self.d))\n",
    "        for k in range(self.K):\n",
    "            self.covars[k] = np.cov(mixtures[k], rowvar=False)\n",
    "        #intialize arrays\n",
    "        self.alpha = self.beta = self.gamma = self.emission = np.zeros((self.N, self.K)) # shape: (N,k)\n",
    "        self.Q = np.random.normal(0,1)\n",
    "    \n",
    "    def maximization(self, X):\n",
    "        # emission probabilities\n",
    "        for n,x in enumerate(X):\n",
    "            for k in range(self.K):\n",
    "                self.emission[n][k] = gaussian(np.asarray(x), self.means[k], np.asarray(self.covars[k]))\n",
    "        # alpha - forward \n",
    "        self.alpha[0] = self.emission[0] * self.pi\n",
    "        for n in range(1,self.N):\n",
    "            self.alpha[n] = self.emission[n] * np.matmul(self.alpha[n-1], self.A)\n",
    "        # beta - backward\n",
    "        self.beta[self.N-1] = np.ones(self.K) # self.beta.shape: (N,k)\n",
    "        for n in range(self.N-2, -1, -1):\n",
    "            self.beta[n] = np.matmul(self.A, self.emission[n+1]*self.beta[n+1])\n",
    "        self.pX = np.sum(self.alpha[self.N-1])\n",
    "        # gamma \n",
    "        self.gamma = self.alpha * self.beta / self.pX\n",
    "        self.Zeta = np.array([self.emission[n]*(self.alpha[n]*(self.A*self.beta[n]).T).T  for n in range(self.N)]) / self.pX\n",
    "        # update parameters\n",
    "        new_pi = self.gamma[0]/np.sum(self.gamma[0])\n",
    "        new_A = np.sum(self.Zeta, axis=0) / np.sum(np.sum(self.Zeta, axis=0), axis=1)\n",
    "        new_covars, new_means = np.zeros((self.K, self.d, self.d)), np.zeros((self.K, self.d))\n",
    "        for k in range(self.K):\n",
    "            # ck = np.matmul(X[n]-self.means[k], np.transpose(X[n]-self.means[k]))\n",
    "            new_covars[k] = np.sum([self.gamma[n][k]*np.tensordot(X[n]-self.means[k], X[n]-self.means[k], axes=0) for n in range(self.N)], axis=0) / np.sum(self.gamma[:,k], axis=0)\n",
    "            #print(np.linalg.det(self.covars[k]))\n",
    "            new_means[k] = np.sum([self.gamma[n][k]*X[n] for n in range(self.N)], axis=0) / np.sum(self.gamma[:,k], axis=0)\n",
    "            \n",
    "        return [new_pi, new_A, new_means, new_covars]\n",
    "        \n",
    "    def likelihood(self, X):\n",
    "        return np.sum(self.alpha[self.N-1]) # beta(ZN)=1\n",
    "    \n",
    "    def expectation(self):\n",
    "        # expectation step\n",
    "        Q = np.sum(self.gamma[0] * self.pi) + np.sum(self.Zeta*self.A) + np.sum(self.gamma * self.emission)\n",
    "        return Q\n",
    "    \n",
    "    def train(self, threshold):\n",
    "        # EM iterations to train the model\n",
    "        [self.pi, self.A, self.means, self.covars] =  self.maximization(self.X[0])\n",
    "        self.new_Q = self.expectation()\n",
    "        print('log likelihood: ', self.Q)\n",
    "        print('Error:', self.new_Q-self.Q)\n",
    "#         while np.abs(self.new_Q - self.Q) > threshold:\n",
    "        count=1\n",
    "        while np.abs(self.Q - self.new_Q) > threshold:\n",
    "            cnt=0\n",
    "            print(self.Q, self.new_Q)\n",
    "            for X in self.X:\n",
    "                cnt+=1\n",
    "                self.Q = self.new_Q\n",
    "                [self.pi, self.A, self.means, self.covars] =  self.maximization(X)\n",
    "                self.new_Q = self.expectation()\n",
    "                print('batch_count', cnt)\n",
    "                print('log likelihood: ', self.new_Q)\n",
    "                print('Error: ', np.abs(self.new_Q-self.Q))\n",
    "                break\n",
    "            count +=1\n",
    "            print('Epoch:', count)\n",
    "            \n",
    "    def get_params(self):\n",
    "        return {'means':self.means, 'covars':self.covars, 'pi':self.pi, 'transitions':self.A}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 956,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 19, 13)\n",
      "log likelihood:  0.3034576874039704\n",
      "Error: 31.157530196841506\n",
      "0.3034576874039704 31.460987884245476\n",
      "batch_count 1\n",
      "log likelihood:  31.460987884245533\n",
      "Error:  5.684341886080802e-14\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in sqrt\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: overflow encountered in exp\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "che, che_test = dataset('che/')()\n",
    "print(che.shape)\n",
    "hmm1 = HMM(K=3, trainset=che)\n",
    "hmm1.train(1e-10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
