{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement an autoencoder with the sparsity constraint. You can build on the MLP implementation from EE5600. Choose your network size appropriately (meaning a size that you can train and test on your computer without running into memory issues)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the MNIST data from keras and downsample\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = np.reshape(x_train, newshape=(*x_train.shape, 1))\n",
    "x_train = tf.image.resize_images(images=x_train, size=(14,14))\n",
    "x = tf.Session().run(x_train)\n",
    "x_train = np.asarray(x, dtype=np.uint8).reshape(x_train.shape[0], 196) / 255.\n",
    "# pd.DataFrame(x_train).to_csv('train.csv', sep=',', index=True, header=False)\n",
    "\n",
    "x_test = np.reshape(x_test, newshape=(*x_test.shape, 1))\n",
    "x_test = tf.image.resize_images(images=x_test, size=(14,14))\n",
    "x = tf.Session().run(x_test)\n",
    "x_test = np.asarray(x, dtype=np.uint8).reshape(x_test.shape[0], 196) / 255.\n",
    "# pd.DataFrame(x_test).to_csv('train.csv', sep=',', index=True, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def show_digits(x, y): # x - 196 dim vector\n",
    "    x, y = np.reshape(x, (14,14)), np.reshape(y, (14,14))\n",
    "    fig = plt.figure(figsize=(4, 10))\n",
    "    fig.add_subplot(1,2,1)\n",
    "    plt.imshow(x, cmap='gray')\n",
    "    fig.add_subplot(1,2,2)\n",
    "    plt.imshow(y, cmap='gray')    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(object):\n",
    "    def __init__(self, input_dim, hidden_dim, learn_rate, sparsity, regularization):\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = input_dim\n",
    "        self.learn_rate = learn_rate\n",
    "        self.s = sparsity\n",
    "        self.Lambda = regularization\n",
    "        # intialize weights\n",
    "        self.A = np.random.normal(0,  1, (self.hidden_dim, self.input_dim))\n",
    "        self.B = np.random.normal(0,  1, (self.output_dim, self.hidden_dim))\n",
    "        self.a0 = np.random.normal(0, 1, self.hidden_dim)\n",
    "        self.b0 = np.random.normal(0, 1, self.output_dim)\n",
    "\n",
    "    def sigmoid(self, t):\n",
    "        return 1/(1  + np.exp(-t))\n",
    "\n",
    "    def dsigmoid(self, t):\n",
    "        sigt = self.sigmoid(t)\n",
    "        return sigt*(1-sigt)\n",
    "\n",
    "    def hidden_layer(self, x):\n",
    "        # A.shape:mxd; x.shape;(d,); so z.shape=(m,)\n",
    "        z = self.sigmoid(np.dot(x, self.A.T) + self.a0) \n",
    "        return z\n",
    "\n",
    "    def forward_pass(self, x):\n",
    "        # B.shape:kxm; z.shape;m; so y_hat.shape=k\n",
    "        y_hat = self.sigmoid(np.dot(self.hidden_layer(x), self.B.T) + self.b0)\n",
    "        return y_hat\n",
    "    \n",
    "    def back_propogate(self, X):\n",
    "        dSSE_A, dSSE_a0 = np.zeros_like(self.A), np.zeros_like(self.a0)\n",
    "        dSSE_B, dSSE_b0 = np.zeros_like(self.B), np.zeros_like(self.b0)\n",
    "        Z = self.hidden_layer(X) # Z.shape = (N,m)\n",
    "        # print('hidden mean',Z[0].shape, np.mean(Z[0]))\n",
    "        dZ = Z * (1-Z) # dZ shape = (N,m)\n",
    "        # y_delta.shape (N,k)\n",
    "        Y_out = self.forward_pass(X)\n",
    "        y_delta = 2*(Y_out-X) * self.dsigmoid(self.b0 + np.dot(Z, self.B.T))\n",
    "        # print(y_delta.shape)\n",
    "        # z_delta.shape (N,m)\n",
    "        z_delta = -dZ * np.matmul(y_delta, self.B) \n",
    "        # z_delta = np.transpose(-dZ.T * np.sum(y_delta, axis=1))\n",
    "        zm = np.mean(Z, axis=0)\n",
    "        # print(zm, zm.shape)\n",
    "        # dKL shape = (N,m) \n",
    "        dKL = self.Lambda * ((-self.s/zm) + ((1-self.s)/(1-zm))) * dZ # shape: (N,m)\n",
    "        #print(dKL.shape)\n",
    "        dSSE_A = np.matmul((z_delta + dKL).T , X)\n",
    "        #print(dSSE_A.shape)\n",
    "        dSSE_a0 = np.sum((z_delta+dKL), axis=0)\n",
    "        #print(dSSE_a0.shape)\n",
    "        dSSE_B = np.matmul(y_delta.T, Z)\n",
    "        # print('dsseB', dSSE_B.shape)\n",
    "        dSSE_b0 = np.sum(y_delta, axis=0)\n",
    "        # update weights \n",
    "        #print('blah', self.A.shape)\n",
    "        A_new = self.A - (self.learn_rate*dSSE_A)\n",
    "        a0_new = self.a0 - (self.learn_rate*dSSE_a0)\n",
    "        B_new = self.B - (self.learn_rate*dSSE_B)\n",
    "        b0_new = self.b0 - (self.learn_rate*dSSE_b0)\n",
    "        return [A_new, a0_new, B_new, b0_new]\n",
    "    \n",
    "    def loss(self, X):\n",
    "        y_hat = self.forward_pass(X)\n",
    "        err = np.sum((X - y_hat)**2)\n",
    "        zm = np.mean(self.hidden_layer(X), axis=0)\n",
    "        regularizer = self.Lambda*np.sum(self.s*np.log(self.s/zm) + (1-self.s)*np.log((1-self.s)/(1-zm)))\n",
    "        return err+regularizer\n",
    "    \n",
    "    def train(self, x_train, epochs, batch_size, shuffle=True): \n",
    "        epoch = 1\n",
    "        N = len(x_train)\n",
    "        while(epoch <= epochs):\n",
    "            if shuffle:\n",
    "                indices = np.arange(N)\n",
    "                np.random.shuffle(indices)\n",
    "                x_train = x_train[indices]\n",
    "            \n",
    "            for batch in np.arange(0, N, batch_size):\n",
    "                X = x_train[batch:batch+batch_size]\n",
    "                Y_hat = self.forward_pass(X)\n",
    "                [self.A, self.a0, self.B, self.b0] = self.back_propogate(X)\n",
    "            \n",
    "            print('Epoch:', epoch, ' Loss:', self.loss(x_train))\n",
    "            if epoch%5==0: show_digits(X[0], Y_hat[0])\n",
    "            epoch += 1\n",
    "        print('Done Training')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SparseAE1 = NN(input_dim=196, hidden_dim=225, learn_rate=1e-4, sparsity=0.1, regularization=1)\n",
    "\n",
    "SparseAE1.train(x_train=x_train, epochs=150, batch_size=300, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    test_out = SparseAE1.forward_pass(x_test[i])\n",
    "    test_rep = SparseAE1.hidden_layer(x_test[i])\n",
    "    show_digits(x_test[i], test_out)\n",
    "    print(test_rep.mean()) # this mean should be close to the chosen sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SparseAE2 = NN(input_dim=196, hidden_dim=256, learn_rate=2e-4, sparsity=0.05, regularization=2)\n",
    "\n",
    "SparseAE2.train(x_train=x_train, epochs=150, batch_size=300, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    test_out = SparseAE2.forward_pass(x_test[i])\n",
    "    test_rep = SparseAE2.hidden_layer(x_test[i])\n",
    "    show_digits(x_test[i], test_out)\n",
    "    print(test_rep.mean()) # this mean should be close to the chosen sparsity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
