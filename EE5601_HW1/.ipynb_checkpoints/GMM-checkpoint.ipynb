{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Mixture Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the expectation maximization (EM) algorithm for estimating the parameters of a Gaussian Mixture Model (GMM). The GMM density is given by\n",
    "$$p(\\mathbf{x}|\\mathbf{θ}) = \\sum_{k=1}^{K} w_k \\mathcal{N}(\\mathbf{x}; \\mathbf{\\mu}_k,\\Sigma_k)$$\n",
    "\n",
    "where $x \\in R^d , \\mathcal{N}(\\mathbf{x};\\mathbf{\\mu},\\Sigma)$ is the multivariate Gaussian distribution with mean vector $\\mathbf{\\mu}$ and covariance matrix $Σ$. The parameter set $\\mathbf{\\theta} = [ w_1 , \\dots, w_d , \\mathbf{μ}_1 ,\\dots, \\mathbf{μ}_K, Σ_1 , \\dots, Σ_K]$ . Your program must accept as inputs the observation matrix $X$ (of size $d \\times N$), the vector dimension $d$ and the mixture size $K$ as inputs, and output the estimated parameter set $\\mathbf{\\hat{\\theta}}$. Generate $X$ on your own and experiment by varying your choices of $\\mathbf{\\theta}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataset\n",
    "d, N, K = 3, 100, 4\n",
    "def generate_dataset(d, N, K):\n",
    "    # means for generating data: (K, d) array with each d-dimensional sub-array as mean vector for kth distribution\n",
    "    known_means = np.array([ np.random.uniform(high=k+1, low=k, size=d) for k in np.arange(K)])\n",
    "    # covariance matrices for generating data\n",
    "    # (K, d,d) array; each dxd matrix is positive semi-definite - valid covariance matrix for kth distribution\n",
    "    A = np.array([np.random.normal(1, 1, (d,d)) for k in np.arange(K)])\n",
    "    known_covs = np.array([np.matmul(P.T, P) for P in A])\n",
    "    # number of samples in kth distribution; rand_k is array of these number of samples per each distribution\n",
    "    while(True): \n",
    "        rand_k = np.random.uniform(high=1, low=0, size=K)\n",
    "        rand_k = N*rand_k/np.sum(rand_k)\n",
    "        rand_k = np.rint(rand_k).astype(np.int)\n",
    "        if np.sum(rand_k) == N : break\n",
    "    # generate N d-dimensional Random Gaussian vectors with means and covariances above\n",
    "    mix = [np.random.multivariate_normal(known_means[i], known_covs[i], size=rand_k[i]) for i in np.arange(K)]#.reshape((N,d))\n",
    "    X = np.concatenate(mix, axis=0)\n",
    "    return X, known_means, known_covs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 5)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, means, covs = generate_dataset(5,1000, 3)\n",
    "X.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
